{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nba_games.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"date\")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"mp.1\"]\n",
    "del df[\"mp_opp.1\"]\n",
    "del df[\"index_opp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Target Column to Represent Team's Next Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(team): \n",
    "    team[\"target\"] = team[\"won\"].shift(-1) # create new column target that represents the team's next game result\n",
    "    return team\n",
    "\n",
    "df = df.groupby(\"team\", group_keys=False).apply(add_target)\n",
    "df[\"target\"][pd.isnull(df[\"target\"])] = 2 # target for last game will be 2\n",
    "df[\"target\"] = df[\"target\"].astype(int, errors=\"ignore\") # turn wins into 0's and 1's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Rid of Null Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = pd.isnull(df).sum()\n",
    "nulls = nulls[nulls > 0]\n",
    "valid_cols = df.columns[~df.columns.isin(nulls.index)]\n",
    "df = df[valid_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "sfs = SequentialFeatureSelector(rr, n_features_to_select=30, direction=\"forward\", cv=split) # start with 0 features, pick best and continue to 30\n",
    "\n",
    "remove_cols = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"] # remove non-statistic cols\n",
    "select_cols = df.columns[~df.columns.isin(remove_cols)]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[select_cols] = scaler.fit_transform(df[select_cols]) # process columns into ranges from 0 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=2, step=1):\n",
    "    all_predictions = [] # list of df predictions\n",
    "\n",
    "    seasons = sorted(df[\"season\"].unique())\n",
    "\n",
    "    for i in range(start, len(seasons), step):\n",
    "        season = seasons[i] # get current season\n",
    "        train = data[data[\"season\"] < season] # all data from previous seasons\n",
    "        test = data[data[\"season\"] == season] # data from current season\n",
    "\n",
    "        model.fit(train[predictors], train[\"target\"]) # take training data and predictors to fit model and predict target\n",
    "\n",
    "        predictions = model.predict(test[predictors]) # generate predictions on test set\n",
    "        predictions = pd.Series(predictions, index=test.index) # convert numpy arr to pandas series\n",
    "\n",
    "        combined = pd.concat([test[\"target\"], predictions], axis=1) # combine target and predictions into one df with two rows\n",
    "        combined.columns = [\"actual\", \"prediction\"]\n",
    "\n",
    "        all_predictions.append(combined) # add to list\n",
    "    return pd.concat(all_predictions) # concat list of df into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Rolling Averages For Each Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_averages(team):\n",
    "    rolling = team.rolling(10).mean() # get average of team's previous 10 games\n",
    "    return rolling\n",
    "\n",
    "df_rolling = df[list(selected_features) + [\"won\", \"team\", \"season\"]]\n",
    "df_rolling\n",
    "\n",
    "df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(get_team_averages, include_groups=False) # group by team and season to compute rolling averages\n",
    "rolling_cols = [f\"{col}_10\" for col in df_rolling.columns] # rename rolling columns\n",
    "df_rolling.columns = rolling_cols # apply new col names\n",
    "\n",
    "df = pd.concat([df, df_rolling], axis=1) # combin to main df\n",
    "df = df.dropna() # drop rows with missing values (team's first 10 games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get The Next Opposing Team's Stats And Merge Into Full DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift value from to previous row\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1) # take value for the game and shift back one row\n",
    "    return next_col\n",
    "\n",
    "# return new row with values shifted back\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name), include_groups=False)\n",
    "\n",
    "df[\"home_next\"] = add_col(df, \"home\") # home for next game\n",
    "df[\"team_opp_next\"] = add_col(df, \"team_opp\") # next opp\n",
    "df[\"date_next\"] = add_col(df, \"date\") # next game date\n",
    "\n",
    "# merge current team and their next opp team\n",
    "# x is the team we are trying to predict and y is the opposing team\n",
    "full = df.merge(df[rolling_cols + [\"team_opp_next\", \"date_next\", \"team\"]], \n",
    "                left_on=[\"team\",\"date_next\"],\n",
    "                right_on=[\"team_opp_next\", \"date_next\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_x</th>\n",
       "      <th>team_opp_next_x</th>\n",
       "      <th>team_y</th>\n",
       "      <th>team_opp_next_y</th>\n",
       "      <th>date_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAC</td>\n",
       "      <td>TOR</td>\n",
       "      <td>TOR</td>\n",
       "      <td>SAC</td>\n",
       "      <td>2015-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOR</td>\n",
       "      <td>SAC</td>\n",
       "      <td>SAC</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEN</td>\n",
       "      <td>NOP</td>\n",
       "      <td>NOP</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2015-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>MIN</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2015-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHI</td>\n",
       "      <td>DAL</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2015-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19261</th>\n",
       "      <td>UTA</td>\n",
       "      <td>NYK</td>\n",
       "      <td>NYK</td>\n",
       "      <td>UTA</td>\n",
       "      <td>2024-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19262</th>\n",
       "      <td>BOS</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2024-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19263</th>\n",
       "      <td>NOP</td>\n",
       "      <td>HOU</td>\n",
       "      <td>HOU</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19264</th>\n",
       "      <td>DEN</td>\n",
       "      <td>OKC</td>\n",
       "      <td>OKC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19265</th>\n",
       "      <td>CHI</td>\n",
       "      <td>CHO</td>\n",
       "      <td>CHO</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19266 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team_x team_opp_next_x team_y team_opp_next_y   date_next\n",
       "0        SAC             TOR    TOR             SAC  2015-11-15\n",
       "1        TOR             SAC    SAC             TOR  2015-11-15\n",
       "2        DEN             NOP    NOP             DEN  2015-11-17\n",
       "3        ORL             MIN    MIN             ORL  2015-11-18\n",
       "4        PHI             DAL    DAL             PHI  2015-11-16\n",
       "...      ...             ...    ...             ...         ...\n",
       "19261    UTA             NYK    NYK             UTA  2024-01-30\n",
       "19262    BOS             IND    IND             BOS  2024-01-30\n",
       "19263    NOP             HOU    HOU             NOP  2024-01-31\n",
       "19264    DEN             OKC    OKC             DEN  2024-01-31\n",
       "19265    CHI             CHO    CHO             CHI  2024-01-31\n",
       "\n",
       "[19266 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[[\"team_x\", \"team_opp_next_x\", \"team_y\", \"team_opp_next_y\", \"date_next\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model and Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mp',\n",
       " 'ft%',\n",
       " 'tov',\n",
       " 'pf',\n",
       " 'usg%',\n",
       " 'trb_max',\n",
       " 'gmsc_max',\n",
       " 'ftr_max',\n",
       " 'trb%_max',\n",
       " 'tov%_max',\n",
       " 'mp_opp',\n",
       " '3p_opp',\n",
       " 'fta_opp',\n",
       " 'stl%_opp',\n",
       " 'usg%_opp',\n",
       " 'pts_max_opp',\n",
       " 'ftr_max_opp',\n",
       " 'stl%_max_opp',\n",
       " 'usg%_10_x',\n",
       " 'gmsc_max_10_x',\n",
       " 'ast%_opp_10_x',\n",
       " 'usg%_opp_10_x',\n",
       " 'ft%_max_opp_10_x',\n",
       " 'won_10_x',\n",
       " 'home_next',\n",
       " 'usg%_10_y',\n",
       " 'gmsc_max_10_y',\n",
       " 'usg%_opp_10_y',\n",
       " 'ft%_max_opp_10_y',\n",
       " 'won_10_y']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_cols = list(full.columns[full.dtypes == \"object\"]) + remove_cols\n",
    "select_cols = full.columns[~full.columns.isin(remove_cols)]\n",
    "\n",
    "sfs.fit(full[select_cols], full[\"target\"])\n",
    "selected_features = list(select_cols[sfs.get_support()])\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Games Using Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6255911178123501"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = backtest(full, rr, selected_features)\n",
    "predictions = predictions[predictions[\"actual\"] != 2]\n",
    "accuracy_score(predictions[\"actual\"], predictions[\"prediction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
